<!DOCTYPE html>
<html lang="bn">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>অধ্যায় ২: Naive GEMM Kernel - CUDA GEMM টিউটোরিয়াল</title>
    <style>
        body {
            max-width: 650px;
            margin: 40px auto;
            padding: 0 20px;
            font-family: 'Kalpurush', 'Noto Sans Bengali', 'SolaimanLipi', Arial, sans-serif;
            font-size: 16px;
            line-height: 1.8;
            color: #333;
        }

        h1 {
            font-size: 32px;
            margin-bottom: 10px;
        }

        h2 {
            font-size: 24px;
            margin-top: 40px;
            margin-bottom: 20px;
        }

        h3 {
            font-size: 20px;
            margin-top: 30px;
            margin-bottom: 15px;
        }

        p {
            margin-bottom: 15px;
        }

        ul, ol {
            margin-bottom: 20px;
            padding-left: 30px;
        }

        li {
            margin-bottom: 10px;
        }

        a {
            color: #0066cc;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        code {
            background: #f4f4f4;
            padding: 2px 6px;
            font-family: 'Courier New', monospace;
            font-size: 14px;
        }

        pre {
            background: #f4f4f4;
            padding: 15px;
            overflow-x: auto;
            margin-bottom: 20px;
            border: 1px solid #ddd;
        }

        pre code {
            background: none;
            padding: 0;
        }

        .nav {
            margin-top: 50px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
            display: flex;
            justify-content: space-between;
        }

        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 40px 0;
        }

        .note {
            background: #f9f9f9;
            border-left: 3px solid #666;
            padding: 10px 15px;
            margin: 20px 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        th, td {
            border: 1px solid #ddd;
            padding: 10px;
            text-align: left;
        }

        th {
            background: #f4f4f4;
        }
    </style>
</head>
<body>
    <p><a href="index.html">← সূচিপত্রে ফিরে যান</a></p>

    <h1>অধ্যায় ২: Naive GEMM Kernel</h1>

    <p>এই অধ্যায়ে আমরা আমাদের প্রথম ম্যাট্রিক্স মাল্টিপ্লিকেশন kernel লিখব। এটি "naive" কারণ এটি সবচেয়ে সহজ সম্ভাব্য পদ্ধতি - প্রতিটি থ্রেড একটি আউটপুট এলিমেন্ট কম্পিউট করবে। এটি দ্রুত হবে না, কিন্তু এটি সঠিক এবং বুঝতে সহজ। এটি আমাদের বেসলাইন যার সাথে আমরা আমাদের অপটিমাইজেশনগুলো তুলনা করব।</p>

    <h2>ম্যাট্রিক্স মাল্টিপ্লিকেশন পুনরায় দেখা</h2>

    <p>মনে করিয়ে দিই, আমরা C = A × B কম্পিউট করছি যেখানে:</p>

    <ul>
        <li>A হলো M × K (M সারি, K কলাম)</li>
        <li>B হলো K × N (K সারি, N কলাম)</li>
        <li>C হলো M × N (M সারি, N কলাম)</li>
    </ul>

    <p>প্রতিটি এলিমেন্ট C[i][j] এভাবে কম্পিউট হয়:</p>

    <pre><code>C[i][j] = A[i][0]*B[0][j] + A[i][1]*B[1][j] + ... + A[i][K-1]*B[K-1][j]</code></pre>

    <p>অথবা লুপ হিসাবে:</p>

    <pre><code>for (int i = 0; i < M; i++) {
    for (int j = 0; j < N; j++) {
        float sum = 0.0f;
        for (int k = 0; k < K; k++) {
            sum += A[i][k] * B[k][j];
        }
        C[i][j] = sum;
    }
}</code></pre>

    <p>এটি CPU-তে তিনটি নেস্টেড লুপ। GPU-তে, আমরা বাইরের দুটি লুপকে প্যারালালাইজ করব - প্রতিটি থ্রেড একটি (i, j) পেয়ার হ্যান্ডেল করবে।</p>

    <h2>Naive Kernel ডিজাইন</h2>

    <p>আমাদের স্ট্র্যাটেজি সরল:</p>

    <ol>
        <li>M × N থ্রেড লঞ্চ করুন (আউটপুট ম্যাট্রিক্সে প্রতিটি এলিমেন্টের জন্য একটি)</li>
        <li>প্রতিটি থ্রেড তার (row, col) পজিশন ক্যালকুলেট করে</li>
        <li>প্রতিটি থ্রেড K এলিমেন্টের উপর লুপ করে একটি ডট প্রোডাক্ট কম্পিউট করে</li>
        <li>রেজাল্ট C[row][col]-এ লিখুন</li>
    </ol>

    <h2>সম্পূর্ণ কোড</h2>

    <p>এখানে সম্পূর্ণ ওয়ার্কিং প্রোগ্রাম রয়েছে যা আপনি Google Colab-এ চালাতে পারবেন:</p>

    <pre><code>%%writefile naive_gemm.cu
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;cuda_runtime.h&gt;

// Naive GEMM kernel: প্রতিটি থ্রেড একটি আউটপুট এলিমেন্ট কম্পিউট করে
__global__ void gemm_naive(int M, int N, int K, 
                           float *A, float *B, float *C) {
    // আউটপুট ম্যাট্রিক্সে এই থ্রেডের row এবং column ক্যালকুলেট করুন
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    
    // Bounds চেক করুন
    if (row < M && col < N) {
        float sum = 0.0f;
        
        // K মাত্রায় ডট প্রোডাক্ট কম্পিউট করুন
        for (int k = 0; k < K; k++) {
            sum += A[row * K + k] * B[k * N + col];
        }
        
        // আউটপুট লিখুন
        C[row * N + col] = sum;
    }
}

// CPU-তে ম্যাট্রিক্স মাল্টিপ্লিকেশন (যাচাইয়ের জন্য)
void gemm_cpu(int M, int N, int K, 
              float *A, float *B, float *C) {
    for (int i = 0; i < M; i++) {
        for (int j = 0; j < N; j++) {
            float sum = 0.0f;
            for (int k = 0; k < K; k++) {
                sum += A[i * K + k] * B[k * N + j];
            }
            C[i * N + j] = sum;
        }
    }
}

// দুটি ম্যাট্রিক্স তুলনা করুন
bool verify_result(float *C_cpu, float *C_gpu, int M, int N) {
    for (int i = 0; i < M * N; i++) {
        // ফ্লোটিং পয়েন্ট ত্রুটির জন্য একটি ছোট tolerance ব্যবহার করুন
        if (fabs(C_cpu[i] - C_gpu[i]) > 1e-3) {
            printf("Mismatch at index %d: CPU=%.6f, GPU=%.6f\n", 
                   i, C_cpu[i], C_gpu[i]);
            return false;
        }
    }
    return true;
}

int main() {
    // ম্যাট্রিক্স মাত্রা
    int M = 512;
    int N = 512;
    int K = 512;
    
    printf("Computing C (%dx%d) = A (%dx%d) * B (%dx%d)\n", 
           M, N, M, K, K, N);
    
    // Host মেমরি অ্যালোকেট করুন
    size_t bytes_A = M * K * sizeof(float);
    size_t bytes_B = K * N * sizeof(float);
    size_t bytes_C = M * N * sizeof(float);
    
    float *h_A = (float*)malloc(bytes_A);
    float *h_B = (float*)malloc(bytes_B);
    float *h_C = (float*)malloc(bytes_C);
    float *h_C_ref = (float*)malloc(bytes_C);
    
    // র‍্যান্ডম ভ্যালু দিয়ে ম্যাট্রিক্স ইনিশিয়ালাইজ করুন
    for (int i = 0; i < M * K; i++) h_A[i] = rand() / (float)RAND_MAX;
    for (int i = 0; i < K * N; i++) h_B[i] = rand() / (float)RAND_MAX;
    
    // Device মেমরি অ্যালোকেট করুন
    float *d_A, *d_B, *d_C;
    cudaMalloc(&d_A, bytes_A);
    cudaMalloc(&d_B, bytes_B);
    cudaMalloc(&d_C, bytes_C);
    
    // ডেটা device-এ কপি করুন
    cudaMemcpy(d_A, h_A, bytes_A, cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, h_B, bytes_B, cudaMemcpyHostToDevice);
    
    // Kernel লঞ্চ কনফিগারেশন
    dim3 threads(16, 16);  // প্রতি ব্লকে 16x16 = 256 থ্রেড
    dim3 blocks((N + threads.x - 1) / threads.x,
                (M + threads.y - 1) / threads.y);
    
    printf("Grid: %dx%d blocks, Block: %dx%d threads\n", 
           blocks.x, blocks.y, threads.x, threads.y);
    
    // Kernel চালান এবং টাইম করুন
    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);
    
    cudaEventRecord(start);
    gemm_naive<<<blocks, threads>>>(M, N, K, d_A, d_B, d_C);
    cudaEventRecord(stop);
    
    cudaEventSynchronize(stop);
    float milliseconds = 0;
    cudaEventElapsedTime(&milliseconds, start, stop);
    
    // রেজাল্ট host-এ ফিরিয়ে আনুন
    cudaMemcpy(h_C, d_C, bytes_C, cudaMemcpyDeviceToHost);
    
    // CPU-তে যাচাই করুন
    printf("Verifying result...\n");
    gemm_cpu(M, N, K, h_A, h_B, h_C_ref);
    
    bool correct = verify_result(h_C_ref, h_C, M, N);
    printf("Result: %s\n", correct ? "CORRECT" : "INCORRECT");
    
    // পারফরম্যান্স মেট্রিক্স
    double gflops = (2.0 * M * N * K) / (milliseconds / 1000.0) / 1e9;
    printf("\nPerformance:\n");
    printf("Time: %.3f ms\n", milliseconds);
    printf("GFLOPS: %.2f\n", gflops);
    
    // ক্লিনআপ
    free(h_A); free(h_B); free(h_C); free(h_C_ref);
    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);
    cudaEventDestroy(start);
    cudaEventDestroy(stop);
    
    return 0;
}</code></pre>

    <p>কম্পাইল এবং রান করুন:</p>

    <pre><code>!nvcc naive_gemm.cu -o naive_gemm
!./naive_gemm</code></pre>

    <h2>কোড বুঝে নেওয়া</h2>

    <h3>Kernel ফাংশন</h3>

    <pre><code>int row = blockIdx.y * blockDim.y + threadIdx.y;
int col = blockIdx.x * blockDim.x + threadIdx.x;</code></pre>

    <p>এটি 2D থ্রেড ইন্ডেক্সিং। আমরা থ্রেডগুলোকে 2D গ্রিডে সাজিয়েছি (যেমন একটি ম্যাট্রিক্স) কারণ আমরা একটি 2D আউটপুট কম্পিউট করছি। প্রতিটি থ্রেড তার আউটপুট ম্যাট্রিক্সের (row, col) পজিশন ক্যালকুলেট করে।</p>

    <pre><code>for (int k = 0; k < K; k++) {
    sum += A[row * K + k] * B[k * N + col];
}</code></pre>

    <p>এটি ডট প্রোডাক্ট। আমরা A-এর একটি row এবং B-এর একটি column জুড়ে লুপ করি। নোট করুন আমরা কীভাবে 1D অ্যারেতে 2D ইন্ডেক্স ম্যাপ করি: <code>A[row][k]</code> হয়ে যায় <code>A[row * K + k]</code>।</p>

    <h3>Grid এবং Block কনফিগারেশন</h3>

    <pre><code>dim3 threads(16, 16);  // 16x16 = 256 থ্রেড প্রতি ব্লক
dim3 blocks((N + threads.x - 1) / threads.x,
            (M + threads.y - 1) / threads.y);</code></pre>

    <p>আমরা 16×16 থ্রেডের ব্লক ব্যবহার করছি (মোট 256 থ্রেড প্রতি ব্লক, যা GPU-র জন্য ভালো)। ব্লকের সংখ্যা আউটপুট সাইজের উপর নির্ভর করে। সিলিং ডিভিশন <code>(N + threads.x - 1) / threads.x</code> নিশ্চিত করে যে আমরা সকল এলিমেন্ট কভার করি এমনকি যদি মাত্রা 16 এর সুনির্দিষ্ট গুণিতক না হয়।</p>

    <h3>টাইমিং</h3>

    <pre><code>cudaEvent_t start, stop;
cudaEventCreate(&start);
cudaEventCreate(&stop);

cudaEventRecord(start);
gemm_naive<<<blocks, threads>>>(M, N, K, d_A, d_B, d_C);
cudaEventRecord(stop);

cudaEventSynchronize(stop);
float milliseconds = 0;
cudaEventElapsedTime(&milliseconds, start, stop);</code></pre>

    <p>CUDA ইভেন্টগুলো GPU কোড সঠিকভাবে টাইম করার উপায়। তারা ডিভাইসে সিঙ্ক্রোনাইজেশন পয়েন্ট তৈরি করে এবং এর মধ্যে সময় পরিমাপ করে।</p>

    <h3>GFLOPS ক্যালকুলেশন</h3>

    <pre><code>double gflops = (2.0 * M * N * K) / (milliseconds / 1000.0) / 1e9;</code></pre>

    <p>GFLOPS (বিলিয়ন ফ্লোটিং পয়েন্ট অপারেশন প্রতি সেকেন্ড) পরিমাপ করে আমরা কত দ্রুত গণনা করছি। প্রতিটি আউটপুট এলিমেন্টের জন্য K multiply এবং K add প্রয়োজন = 2K অপারেশন। মোট: 2×M×N×K অপারেশন।</p>

    <h2>প্রত্যাশিত আউটপুট</h2>

    <p>512×512 ম্যাট্রিক্সের জন্য, আপনার দেখা উচিত:</p>

    <pre><code>Computing C (512x512) = A (512x512) * B (512x512)
Grid: 32x32 blocks, Block: 16x16 threads
Verifying result...
Result: CORRECT

Performance:
Time: 2.xxx ms
GFLOPS: ~100-150</code></pre>

    <h2>পারফরম্যান্স বিশ্লেষণ</h2>

    <p>512×512 ম্যাট্রিক্স মাল্টিপ্লিকেশনে 2 × 512 × 512 × 512 = 268 মিলিয়ন FLOP প্রয়োজন।</p>

    <p>T4 GPU-র তাত্ত্বিক পিক: ~8100 GFLOPS (FP32)</p>

    <p>আমাদের naive kernel: ~100-150 GFLOPS</p>

    <p>এটি পিকের মাত্র ~1.5-2%! কেন এত ধীর?</p>

    <ul>
        <li><strong>মেমরি ব্যান্ডউইথ:</strong> প্রতিটি FLOP-এর জন্য, আমরা গ্লোবাল মেমরি থেকে 2টি float পড়ি (A এবং B থেকে একটি করে)</li>
        <li><strong>কোন পুনর্ব্যবহার নেই:</strong> আমরা A এবং B-এর একই এলিমেন্ট বারবার পড়ি</li>
        <li><strong>লেটেন্সি:</strong> গ্লোবাল মেমরি এক্সেস ধীর (~400-800 সাইকেল)</li>
        <li><strong>কোন coalescing নেই:</strong> B থেকে পড়া stride এক্সেস (পরবর্তী অধ্যায়ে আরও)</li>
    </ul>

    <h2>বিভিন্ন সাইজ পরীক্ষা করা</h2>

    <p>বিভিন্ন ম্যাট্রিক্স সাইজ চেষ্টা করুন:</p>

    <table>
        <tr>
            <th>সাইজ</th>
            <th>FLOP</th>
            <th>প্রত্যাশিত সময় (T4)</th>
        </tr>
        <tr>
            <td>256×256</td>
            <td>33.5M</td>
            <td>~0.5 ms</td>
        </tr>
        <tr>
            <td>512×512</td>
            <td>268M</td>
            <td>~2 ms</td>
        </tr>
        <tr>
            <td>1024×1024</td>
            <td>2.15B</td>
            <td>~15 ms</td>
        </tr>
        <tr>
            <td>2048×2048</td>
            <td>17.2B</td>
            <td>~120 ms</td>
        </tr>
    </table>

    <div class="note">
        <p><strong>লক্ষ্য করুন:</strong> বড় ম্যাট্রিক্সে GFLOPS কিছুটা উন্নত হয় কারণ GPU আরো ভালোভাবে ব্যবহৃত হয় (আরো থ্রেড চলছে), কিন্তু আমরা এখনও পিক পারফরম্যান্সের কাছাকাছি কোথাও নেই।</p>
    </div>

    <h2>পরবর্তী কী?</h2>

    <p>আমরা একটি কার্যকর কিন্তু ধীর GEMM kernel লিখেছি। পরবর্তী অধ্যায়ে, আমরা T4 GPU আর্কিটেকচার অধ্যয়ন করব - মেমরি হায়ারার্কি, SM, ওয়ার্প - এবং বুঝব কেন আমাদের naive implementation এত ধীর। এই জ্ঞান আমাদের পরবর্তী অধ্যায়ে পারফরম্যান্স উল্লেখযোগ্যভাবে উন্নত করতে অপটিমাইজেশন করতে গাইড করবে।</p>

    <div class="note">
        <p><strong>অনুশীলন:</strong></p>
        <ul>
            <li>বিভিন্ন ব্লক সাইজ চেষ্টা করুন (8×8, 32×32). পারফরম্যান্স কীভাবে পরিবর্তন হয়?</li>
            <li>আয়তক্ষেত্রাকার ম্যাট্রিক্স চেষ্টা করুন (যেমন 512×1024 × 1024×256)</li>
            <li>4096×4096 ম্যাট্রিক্স চেষ্টা করুন। এটি কতক্ষণ নেয়?</li>
        </ul>
    </div>

    <div class="nav">
        <a href="chapter1.html">← অধ্যায় ১</a>
        <a href="chapter3.html">অধ্যায় ৩: T4 GPU আর্কিটেকচার বোঝা →</a>
    </div>

</body>
</html>